{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 04: Matrix Addition with 2D Grids\n",
    "## Phase 1: Foundations - Thread Hierarchy & Kernel Basics\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Understand 2D thread blocks and grids\n",
    "- Calculate 2D thread indices\n",
    "- Work with matrices in GPU memory\n",
    "- Use dim3 for multi-dimensional configurations\n",
    "- Handle 2D data structures efficiently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept: 2D Thread Organization\n",
    "\n",
    "**2D Thread Indexing:**\n",
    "```cuda\n",
    "int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "```\n",
    "\n",
    "**dim3 Structure:**\n",
    "```cuda\n",
    "dim3 blockDim(16, 16);  // 16x16 threads per block\n",
    "dim3 gridDim(4, 4);     // 4x4 blocks\n",
    "kernel<<<gridDim, blockDim>>>();\n",
    "```\n",
    "\n",
    "**Matrix Layout in Memory:**\n",
    "- Row-major order: element[i][j] at index i * width + j\n",
    "- Contiguous in memory for efficient access"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Simple 2D Matrix Addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cu\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "__global__ void matrixAdd(float *a, float *b, float *c, int width, int height) {\n",
    "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    \n",
    "    if (row < height && col < width) {\n",
    "        int idx = row * width + col;\n",
    "        c[idx] = a[idx] + b[idx];\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int width = 64;\n",
    "    int height = 64;\n",
    "    int size = width * height * sizeof(float);\n",
    "    \n",
    "    // Allocate host memory\n",
    "    float *h_a = (float*)malloc(size);\n",
    "    float *h_b = (float*)malloc(size);\n",
    "    float *h_c = (float*)malloc(size);\n",
    "    \n",
    "    // Initialize matrices\n",
    "    for (int i = 0; i < height * width; i++) {\n",
    "        h_a[i] = i * 1.0f;\n",
    "        h_b[i] = i * 2.0f;\n",
    "    }\n",
    "    \n",
    "    // Allocate device memory\n",
    "    float *d_a, *d_b, *d_c;\n",
    "    cudaMalloc(&d_a, size);\n",
    "    cudaMalloc(&d_b, size);\n",
    "    cudaMalloc(&d_c, size);\n",
    "    \n",
    "    // Copy to device\n",
    "    cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_b, h_b, size, cudaMemcpyHostToDevice);\n",
    "    \n",
    "    // Configure 2D kernel launch\n",
    "    dim3 blockDim(16, 16);\n",
    "    dim3 gridDim((width + blockDim.x - 1) / blockDim.x,\n",
    "                 (height + blockDim.y - 1) / blockDim.y);\n",
    "    \n",
    "    printf(\"Matrix size: %dx%d\\n\", width, height);\n",
    "    printf(\"Block dimensions: %dx%d\\n\", blockDim.x, blockDim.y);\n",
    "    printf(\"Grid dimensions: %dx%d\\n\", gridDim.x, gridDim.y);\n",
    "    \n",
    "    matrixAdd<<<gridDim, blockDim>>>(d_a, d_b, d_c, width, height);\n",
    "    \n",
    "    // Copy result back\n",
    "    cudaMemcpy(h_c, d_c, size, cudaMemcpyDeviceToHost);\n",
    "    \n",
    "    // Verify\n",
    "    bool correct = true;\n",
    "    for (int i = 0; i < height * width; i++) {\n",
    "        if (h_c[i] != h_a[i] + h_b[i]) {\n",
    "            correct = false;\n",
    "            break;\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    printf(\"Result: %s\\n\", correct ? \"CORRECT\" : \"INCORRECT\");\n",
    "    \n",
    "    free(h_a); free(h_b); free(h_c);\n",
    "    cudaFree(d_a); cudaFree(d_b); cudaFree(d_c);\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Visualizing Thread Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cu\n",
    "#include <stdio.h>\n",
    "\n",
    "__global__ void printThreadInfo(int width, int height) {\n",
    "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    \n",
    "    if (row < height && col < width) {\n",
    "        int idx = row * width + col;\n",
    "        if (idx < 10) {  // Print first 10 threads\n",
    "            printf(\"Element[%d][%d] (idx=%d): Block(%d,%d) Thread(%d,%d)\\n\",\n",
    "                   row, col, idx,\n",
    "                   blockIdx.y, blockIdx.x,\n",
    "                   threadIdx.y, threadIdx.x);\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int width = 8;\n",
    "    int height = 8;\n",
    "    \n",
    "    dim3 blockDim(4, 4);\n",
    "    dim3 gridDim((width + blockDim.x - 1) / blockDim.x,\n",
    "                 (height + blockDim.y - 1) / blockDim.y);\n",
    "    \n",
    "    printf(\"Launching %dx%d grid of %dx%d blocks\\n\\n\",\n",
    "           gridDim.x, gridDim.y, blockDim.x, blockDim.y);\n",
    "    \n",
    "    printThreadInfo<<<gridDim, blockDim>>>(width, height);\n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Large Matrix Addition with Timing"
   ]
  },
  {
   "cell_"cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cu\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "__global__ void matrixAdd(float *a, float *b, float *c, int width, int height) {\n",
    "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    \n",
    "    if (row < height && col < width) {\n",
    "        int idx = row * width + col;\n",
    "        c[idx] = a[idx] + b[idx];\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int width = 4096;\n",
    "    int height = 4096;\n",
    "    size_t size = width * height * sizeof(float);\n",
    "    \n",
    "    printf(\"Matrix size: %dx%d (%.2f MB)\\n\", width, height, size / 1024.0 / 1024.0);\n",
    "    \n",
    "    float *h_a = (float*)malloc(size);\n",
    "    float *h_b = (float*)malloc(size);\n",
    "    float *h_c = (float*)malloc(size);\n",
    "    \n",
    "    for (int i = 0; i < height * width; i++) {\n",
    "        h_a[i] = rand() / (float)RAND_MAX;\n",
    "        h_b[i] = rand() / (float)RAND_MAX;\n",
    "    }\n",
    "    \n",
    "    float *d_a, *d_b, *d_c;\n",
    "    cudaMalloc(&d_a, size);\n",
    "    cudaMalloc(&d_b, size);\n",
    "    cudaMalloc(&d_c, size);\n",
    "    \n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "    \n",
    "    // Time memory transfer\n",
    "    cudaEventRecord(start);\n",
    "    cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_b, h_b, size, cudaMemcpyHostToDevice);\n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "    float transferTime;\n",
    "    cudaEventElapsedTime(&transferTime, start, stop);\n",
    "    \n",
    "    // Time kernel\n",
    "    dim3 blockDim(16, 16);\n",
    "    dim3 gridDim((width + blockDim.x - 1) / blockDim.x,\n",
    "                 (height + blockDim.y - 1) / blockDim.y);\n",
    "    \n",
    "    cudaEventRecord(start);\n",
    "    matrixAdd<<<gridDim, blockDim>>>(d_a, d_b, d_c, width, height);\n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "    float kernelTime;\n",
    "    cudaEventElapsedTime(&kernelTime, start, stop);\n",
    "    \n",
    "    cudaMemcpy(h_c, d_c, size, cudaMemcpyDeviceToHost);\n",
    "    \n",
    "    // Verify\n",
    "    float maxError = 0.0f;\n",
    "    for (int i = 0; i < 1000; i++) {  // Check sample\n",
    "        int idx = rand() % (height * width);\n",
    "        float error = abs(h_c[idx] - (h_a[idx] + h_b[idx]));\n",
    "        if (error > maxError) maxError = error;\n",
    "    }\n",
    "    \n",
    "    printf(\"\\nPerformance:\\n\");\n",
    "    printf(\"Transfer time: %.2f ms\\n\", transferTime);\n",
    "    printf(\"Kernel time: %.2f ms\\n\", kernelTime);\n",
    "    printf(\"Total time: %.2f ms\\n\", transferTime + kernelTime);\n",
    "    printf(\"Max error: %e\\n\", maxError);\n",
    "    \n",
    "    free(h_a); free(h_b); free(h_c);\n",
    "    cudaFree(d_a); cudaFree(d_b); cudaFree(d_c);\n",
    "    cudaEventDestroy(start);\n",
    "    cudaEventDestroy(stop);\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Different Block Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cu\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "__global__ void matrixAdd(float *a, float *b, float *c, int width, int height) {\n",
    "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    \n",
    "    if (row < height && col < width) {\n",
    "        int idx = row * width + col;\n",
    "        c[idx] = a[idx] + b[idx];\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int width = 2048;\n",
    "    int height = 2048;\n",
    "    size_t size = width * height * sizeof(float);\n",
    "    \n",
    "    float *h_a = (float*)malloc(size);\n",
    "    float *h_b = (float*)malloc(size);\n",
    "    float *h_c = (float*)malloc(size);\n",
    "    \n",
    "    for (int i = 0; i < height * width; i++) {\n",
    "        h_a[i] = i * 1.0f;\n",
    "        h_b[i] = i * 2.0f;\n",
    "    }\n",
    "    \n",
    "    float *d_a, *d_b, *d_c;\n",
    "    cudaMalloc(&d_a, size);\n",
    "    cudaMalloc(&d_b, size);\n",
    "    cudaMalloc(&d_c, size);\n",
    "    \n",
    "    cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_b, h_b, size, cudaMemcpyHostToDevice);\n",
    "    \n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "    \n",
    "    printf(\"Testing different block configurations:\\n\");\n",
    "    printf(\"Matrix size: %dx%d\\n\\n\", width, height);\n",
    "    \n",
    "    int configs[][2] = {{8, 8}, {16, 16}, {32, 32}, {16, 32}, {32, 16}};\n",
    "    \n",
    "    for (int i = 0; i < 5; i++) {\n",
    "        dim3 blockDim(configs[i][0], configs[i][1]);\n",
    "        dim3 gridDim((width + blockDim.x - 1) / blockDim.x,\n",
    "                     (height + blockDim.y - 1) / blockDim.y);\n",
    "        \n",
    "        cudaEventRecord(start);\n",
    "        matrixAdd<<<gridDim, blockDim>>>(d_a, d_b, d_c, width, height);\n",
    "        cudaEventRecord(stop);\n",
    "        cudaEventSynchronize(stop);\n",
    "        \n",
    "        float milliseconds = 0;\n",
    "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "        \n",
    "        printf(\"Block %dx%d: Grid %dx%d, Time: %.3f ms\\n\",\n",
    "               blockDim.x, blockDim.y, gridDim.x, gridDim.y, milliseconds);\n",
    "    }\n",
    "    \n",
    "    free(h_a); free(h_b); free(h_c);\n",
    "    cudaFree(d_a); cudaFree(d_b); cudaFree(d_c);\n",
    "    cudaEventDestroy(start);\n",
    "    cudaEventDestroy(stop);\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical Exercise\n",
    "\n",
    "**Exercise 1:** Implement matrix subtraction using 2D indexing\n",
    "\n",
    "**Exercise 2:** Implement matrix transpose (swap rows and columns)\n",
    "\n",
    "**Exercise 3:** Find the optimal block size for your GPU\n",
    "\n",
    "**Exercise 4:** Implement a kernel that prints the thread ID at each corner of the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cu\n",
    "// Your solution here\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "__global__ void matrixOp(float *a, float *b, float *c, int width, int height) {\n",
    "    // TODO: Implement your operation\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    // TODO: Implement your solution\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **2D indexing**: row = blockIdx.y * blockDim.y + threadIdx.y, col = blockIdx.x * blockDim.x + threadIdx.x\n",
    "2. **dim3** struct allows specifying 2D/3D dimensions\n",
    "3. Matrix stored in **row-major order**: idx = row * width + col\n",
    "4. Always check **both row and column boundaries**\n",
    "5. Common block sizes: 16x16, 32x32 (256-1024 threads)\n",
    "6. Block dimensions affect performance\n",
    "7. Grid dimensions calculated by rounding up division"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "In the next notebook, we'll learn:\n",
    "- Advanced thread indexing patterns\n",
    "- 3D thread organization\n",
    "- Stride patterns for large data\n",
    "- Grid-stride loops\n",
    "\n",
    "Continue to: **05_thread_indexing.ipynb**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "*Use this space to write your own notes and observations:*\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
