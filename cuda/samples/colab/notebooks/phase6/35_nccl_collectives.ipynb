{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 35: NCCL Multi-GPU Communication",
    "## Phase 6: Streams & Concurrency",
    "",
    "**Learning Objectives:**",
    "- Understand NCCL",
    "- Learn collectives",
    "- Master multi-GPU comm",
    "- Apply concepts in practical scenarios",
    "- Measure and analyze performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept: NCCL Multi-GPU Communication",
    "",
    "**Topics Covered:**",
    "- NCCL",
    "- collectives",
    "- multi-GPU comm",
    "",
    "**Key Concepts:**",
    "This notebook covers NCCL in the context of Phase 6: Streams & Concurrency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Basic NCCL Multi-GPU Communication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cu\n#include <stdio.h>\n\n__global__ void kernel() {\n    printf(\"Example for: nccl\\n\");\n}\n\nint main() {\n    printf(\"=== Nccl ===\\n\\n\");\n\n    kernel<<<1, 32>>>();\n    cudaDeviceSynchronize();\n\n    printf(\"\\nExample completed successfully!\\n\");\n    return 0;\n}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical Exercise",
    "",
    "Complete the following exercises to practice the concepts learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cu\n#include <stdio.h>\n\n__global__ void kernel() {\n    printf(\"Example for: nccl\\n\");\n}\n\nint main() {\n    printf(\"=== Nccl ===\\n\\n\");\n\n    kernel<<<1, 32>>>();\n    cudaDeviceSynchronize();\n\n    printf(\"\\nExample completed successfully!\\n\");\n    return 0;\n}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n\n1. NCCL = NVIDIA Collective Communications Library\n2. All-reduce, broadcast, gather operations\n3. Multi-GPU and multi-node\n4. Critical for distributed training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps",
    "",
    "Continue to: **36_next_topic.ipynb**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes",
    "",
    "*Use this space to write your own notes and observations:*",
    "",
    "---",
    "",
    "",
    "",
    "---"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}