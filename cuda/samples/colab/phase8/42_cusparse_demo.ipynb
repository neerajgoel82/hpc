{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 42: cuSPARSE for Sparse Matrices",
    "## Phase 8: Real-World Applications",
    "",
    "**Learning Objectives:**",
    "- Understand cuSPARSE",
    "- Learn sparse matrices",
    "- Master CSR format",
    "- Apply concepts in practical scenarios",
    "- Measure and analyze performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept: cuSPARSE for Sparse Matrices",
    "",
    "**Topics Covered:**",
    "- cuSPARSE",
    "- sparse matrices",
    "- CSR format",
    "",
    "**Key Concepts:**",
    "This notebook covers cuSPARSE in the context of Phase 8: Real-World Applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Basic cuSPARSE for Sparse Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "%%cu\n#include <stdio.h>\n#include <stdlib.h>\n#include <cuda_runtime.h>\n#include <cusparse.h>\n\n#define CUDA_CHECK(call) \\\n    do { \\\n        cudaError_t err = call; \\\n        if (err != cudaSuccess) { \\\n            fprintf(stderr, \"CUDA error at %s:%d: %s\\n\", \\\n                    __FILE__, __LINE__, cudaGetErrorString(err)); \\\n            exit(EXIT_FAILURE); \\\n        } \\\n    } while(0)\n\nint main() {\n    printf(\"=== cuSPARSE: Sparse Matrix Operations ===\\n\\n\");\n\n    // Create a sparse matrix in CSR format\n    // Matrix: 4x4 with only 6 non-zero elements\n    //   [1  0  2  0]\n    //   [0  3  0  0]\n    //   [0  0  4  5]\n    //   [6  0  0  7]\n\n    const int rows = 4;\n    const int cols = 4;\n    const int nnz = 7;  // number of non-zeros\n\n    // CSR format\n    int h_csrRowPtr[5] = {0, 2, 3, 5, 7};  // row pointers\n    int h_csrColInd[7] = {0, 2, 1, 2, 3, 0, 3};  // column indices\n    float h_csrVal[7] = {1.0f, 2.0f, 3.0f, 4.0f, 5.0f, 6.0f, 7.0f};  // values\n\n    // Dense vector for multiplication\n    float h_x[4] = {1.0f, 2.0f, 3.0f, 4.0f};\n    float h_y[4] = {0.0f, 0.0f, 0.0f, 0.0f};\n\n    // Allocate device memory\n    int *d_csrRowPtr, *d_csrColInd;\n    float *d_csrVal, *d_x, *d_y;\n\n    CUDA_CHECK(cudaMalloc(&d_csrRowPtr, (rows + 1) * sizeof(int)));\n    CUDA_CHECK(cudaMalloc(&d_csrColInd, nnz * sizeof(int)));\n    CUDA_CHECK(cudaMalloc(&d_csrVal, nnz * sizeof(float)));\n    CUDA_CHECK(cudaMalloc(&d_x, cols * sizeof(float)));\n    CUDA_CHECK(cudaMalloc(&d_y, rows * sizeof(float)));\n\n    // Copy to device\n    CUDA_CHECK(cudaMemcpy(d_csrRowPtr, h_csrRowPtr, (rows + 1) * sizeof(int),\n                          cudaMemcpyHostToDevice));\n    CUDA_CHECK(cudaMemcpy(d_csrColInd, h_csrColInd, nnz * sizeof(int),\n                          cudaMemcpyHostToDevice));\n    CUDA_CHECK(cudaMemcpy(d_csrVal, h_csrVal, nnz * sizeof(float),\n                          cudaMemcpyHostToDevice));\n    CUDA_CHECK(cudaMemcpy(d_x, h_x, cols * sizeof(float), cudaMemcpyHostToDevice));\n\n    // Create cuSPARSE handle\n    cusparseHandle_t handle;\n    cusparseCreate(&handle);\n\n    // Create matrix descriptor\n    cusparseMatDescr_t descr;\n    cusparseCreateMatDescr(&descr);\n    cusparseSetMatType(descr, CUSPARSE_MATRIX_TYPE_GENERAL);\n    cusparseSetMatIndexBase(descr, CUSPARSE_INDEX_BASE_ZERO);\n\n    // Sparse matrix-vector multiplication: y = A * x\n    float alpha = 1.0f;\n    float beta = 0.0f;\n\n    cudaEvent_t start, stop;\n    cudaEventCreate(&start);\n    cudaEventCreate(&stop);\n\n    cudaEventRecord(start);\n    cusparseScsrmv(handle, CUSPARSE_OPERATION_NON_TRANSPOSE,\n                   rows, cols, nnz, &alpha, descr,\n                   d_csrVal, d_csrRowPtr, d_csrColInd,\n                   d_x, &beta, d_y);\n    cudaEventRecord(stop);\n    cudaEventSynchronize(stop);\n\n    float ms;\n    cudaEventElapsedTime(&ms, start, stop);\n\n    // Copy result back\n    CUDA_CHECK(cudaMemcpy(h_y, d_y, rows * sizeof(float), cudaMemcpyDeviceToHost));\n\n    printf(\"Sparse matrix-vector multiply: y = A * x\\n\");\n    printf(\"Matrix size: %dx%d\\n\", rows, cols);\n    printf(\"Non-zeros: %d (%.1f%% sparse)\\n\", nnz,\n           100.0f * (1.0f - (float)nnz / (rows * cols)));\n    printf(\"\\nResult vector y:\\n\");\n    for (int i = 0; i < rows; i++) {\n        printf(\"  y[%d] = %.1f\\n\", i, h_y[i]);\n    }\n    printf(\"\\nComputation time: %.3f ms\\n\", ms);\n\n    // Cleanup\n    cusparseDestroyMatDescr(descr);\n    cusparseDestroy(handle);\n    cudaFree(d_csrRowPtr);\n    cudaFree(d_csrColInd);\n    cudaFree(d_csrVal);\n    cudaFree(d_x);\n    cudaFree(d_y);\n    cudaEventDestroy(start);\n    cudaEventDestroy(stop);\n\n    return 0;\n}\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical Exercise",
    "",
    "Complete the following exercises to practice the concepts learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cu\n#include <stdio.h>\n#include <stdlib.h>\n#include <cuda_runtime.h>\n\n#define CUDA_CHECK(call) \\\n    do { \\\n        cudaError_t err = call; \\\n        if (err != cudaSuccess) { \\\n            fprintf(stderr, \"CUDA error at %s:%d: %s\\n\", \\\n                    __FILE__, __LINE__, cudaGetErrorString(err)); \\\n            exit(EXIT_FAILURE); \\\n        } \\\n    } while(0)\n\n__global__ void kernel(float *data, int n) {\n    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n    if (idx < n) {\n        data[idx] = data[idx] * 2.0f;\n    }\n}\n\nint main() {\n    printf(\"=== Cusparse Demo ===\\n\\n\");\n\n    int n = 1000000;\n    size_t size = n * sizeof(float);\n\n    float *h_data = (float*)malloc(size);\n    for (int i = 0; i < n; i++) h_data[i] = i;\n\n    float *d_data;\n    CUDA_CHECK(cudaMalloc(&d_data, size));\n    CUDA_CHECK(cudaMemcpy(d_data, h_data, size, cudaMemcpyHostToDevice));\n\n    cudaEvent_t start, stop;\n    cudaEventCreate(&start);\n    cudaEventCreate(&stop);\n\n    int threads = 256;\n    int blocks = (n + threads - 1) / threads;\n\n    cudaEventRecord(start);\n    kernel<<<blocks, threads>>>(d_data, n);\n    cudaEventRecord(stop);\n    cudaEventSynchronize(stop);\n\n    float ms;\n    cudaEventElapsedTime(&ms, start, stop);\n\n    CUDA_CHECK(cudaMemcpy(h_data, d_data, size, cudaMemcpyDeviceToHost));\n\n    printf(\"Processed %d elements in %.2f ms\\n\", n, ms);\n    printf(\"Bandwidth: %.2f GB/s\\n\", (size * 2 / 1e9) / (ms / 1000.0));\n\n    free(h_data);\n    cudaFree(d_data);\n    cudaEventDestroy(start);\n    cudaEventDestroy(stop);\n\n    return 0;\n}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n\n1. cuSPARSE = sparse matrix library\n2. Efficient sparse matrix operations\n3. CSR, COO formats\n4. SpMV (Sparse Matrix-Vector multiply)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps",
    "",
    "Continue to: **43_next_topic.ipynb**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes",
    "",
    "*Use this space to write your own notes and observations:*",
    "",
    "---",
    "",
    "",
    "",
    "---"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}