{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 02: Device Query and GPU Properties\n",
    "## Phase 1: Foundations - CUDA Architecture Basics\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Query and display GPU device properties\n",
    "- Understand GPU architecture components (SMs, cores, warps)\n",
    "- Learn about memory hierarchy and sizes\n",
    "- Make informed decisions about kernel configuration\n",
    "- Understand compute capability and its significance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept: GPU Architecture\n",
    "\n",
    "**NVIDIA GPU Architecture Components:**\n",
    "\n",
    "1. **Streaming Multiprocessors (SMs)**: The core processing units\n",
    "2. **CUDA Cores**: Individual processing units within an SM\n",
    "3. **Warp**: Group of 32 threads that execute together\n",
    "4. **Memory Hierarchy**:\n",
    "   - Registers (fastest, per-thread)\n",
    "   - Shared Memory (fast, per-block)\n",
    "   - L1/L2 Cache\n",
    "   - Global Memory (slowest, all threads)\n",
    "\n",
    "**Compute Capability**: Version number indicating GPU features\n",
    "- Format: Major.Minor (e.g., 7.5, 8.0, 8.6)\n",
    "- Higher numbers = newer architecture with more features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Count Available Devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cu\n",
    "#include <stdio.h>\n",
    "\n",
    "int main() {\n",
    "    int deviceCount = 0;\n",
    "    cudaError_t error = cudaGetDeviceCount(&deviceCount);\n",
    "    \n",
    "    if (error != cudaSuccess) {\n",
    "        printf(\"cudaGetDeviceCount failed: %s\\n\", cudaGetErrorString(error));\n",
    "        return 1;\n",
    "    }\n",
    "    \n",
    "    printf(\"Number of CUDA devices: %d\\n\\n\", deviceCount);\n",
    "    \n",
    "    if (deviceCount == 0) {\n",
    "        printf(\"No CUDA-capable devices found!\\n\");\n",
    "        return 1;\n",
    "    }\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Basic Device Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cu\n",
    "#include <stdio.h>\n",
    "\n",
    "int main() {\n",
    "    int deviceCount;\n",
    "    cudaGetDeviceCount(&deviceCount);\n",
    "    \n",
    "    for (int dev = 0; dev < deviceCount; dev++) {\n",
    "        cudaDeviceProp prop;\n",
    "        cudaGetDeviceProperties(&prop, dev);\n",
    "        \n",
    "        printf(\"Device %d: %s\\n\", dev, prop.name);\n",
    "        printf(\"  Compute Capability: %d.%d\\n\", prop.major, prop.minor);\n",
    "        printf(\"  Total Global Memory: %.2f GB\\n\", \n",
    "               prop.totalGlobalMem / 1024.0 / 1024.0 / 1024.0);\n",
    "        printf(\"  Multiprocessors: %d\\n\", prop.multiProcessorCount);\n",
    "        printf(\"  Max Threads per Block: %d\\n\", prop.maxThreadsPerBlock);\n",
    "        printf(\"\\n\");\n",
    "    }\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Comprehensive Device Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cu\n",
    "#include <stdio.h>\n",
    "\n",
    "int main() {\n",
    "    int dev = 0;\n",
    "    cudaDeviceProp prop;\n",
    "    cudaGetDeviceProperties(&prop, dev);\n",
    "    \n",
    "    printf(\"=== Device %d: %s ===\\n\\n\", dev, prop.name);\n",
    "    \n",
    "    // Compute capability\n",
    "    printf(\"Compute Capability: %d.%d\\n\", prop.major, prop.minor);\n",
    "    \n",
    "    // Memory information\n",
    "    printf(\"\\n--- Memory Information ---\\n\");\n",
    "    printf(\"Total Global Memory: %.2f GB\\n\", \n",
    "           prop.totalGlobalMem / 1024.0 / 1024.0 / 1024.0);\n",
    "    printf(\"Shared Memory per Block: %zu bytes\\n\", prop.sharedMemPerBlock);\n",
    "    printf(\"Constant Memory: %zu bytes\\n\", prop.totalConstMem);\n",
    "    printf(\"Registers per Block: %d\\n\", prop.regsPerBlock);\n",
    "    printf(\"L2 Cache Size: %d bytes\\n\", prop.l2CacheSize);\n",
    "    \n",
    "    // Execution configuration\n",
    "    printf(\"\\n--- Execution Configuration ---\\n\");\n",
    "    printf(\"Multiprocessors: %d\\n\", prop.multiProcessorCount);\n",
    "    printf(\"CUDA Cores per SM: ~%d (approx)\\n\", \n",
    "           prop.major >= 7 ? 64 : 128);\n",
    "    printf(\"Warp Size: %d threads\\n\", prop.warpSize);\n",
    "    printf(\"Max Threads per Block: %d\\n\", prop.maxThreadsPerBlock);\n",
    "    printf(\"Max Threads per SM: %d\\n\", prop.maxThreadsPerMultiProcessor);\n",
    "    printf(\"Max Blocks per SM: %d\\n\", prop.maxBlocksPerMultiProcessor);\n",
    "    \n",
    "    // Grid and block dimensions\n",
    "    printf(\"\\n--- Grid and Block Limits ---\\n\");\n",
    "    printf(\"Max Grid Size: (%d, %d, %d)\\n\", \n",
    "           prop.maxGridSize[0], prop.maxGridSize[1], prop.maxGridSize[2]);\n",
    "    printf(\"Max Block Dimensions: (%d, %d, %d)\\n\", \n",
    "           prop.maxThreadsDim[0], prop.maxThreadsDim[1], prop.maxThreadsDim[2]);\n",
    "    \n",
    "    // Performance features\n",
    "    printf(\"\\n--- Performance Features ---\\n\");\n",
    "    printf(\"Clock Rate: %.2f GHz\\n\", prop.clockRate / 1000000.0);\n",
    "    printf(\"Memory Clock Rate: %.2f GHz\\n\", prop.memoryClockRate / 1000000.0);\n",
    "    printf(\"Memory Bus Width: %d-bit\\n\", prop.memoryBusWidth);\n",
    "    printf(\"Peak Memory Bandwidth: %.2f GB/s\\n\", \n",
    "           2.0 * prop.memoryClockRate * (prop.memoryBusWidth / 8) / 1.0e6);\n",
    "    \n",
    "    // Capabilities\n",
    "    printf(\"\\n--- Capabilities ---\\n\");\n",
    "    printf(\"Concurrent Kernels: %s\\n\", prop.concurrentKernels ? \"Yes\" : \"No\");\n",
    "    printf(\"ECC Enabled: %s\\n\", prop.ECCEnabled ? \"Yes\" : \"No\");\n",
    "    printf(\"Unified Addressing: %s\\n\", prop.unifiedAddressing ? \"Yes\" : \"No\");\n",
    "    printf(\"Managed Memory: %s\\n\", prop.managedMemory ? \"Yes\" : \"No\");\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Selecting and Setting Active Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cu\n",
    "#include <stdio.h>\n",
    "\n",
    "__global__ void identifyDevice() {\n",
    "    printf(\"Hello from the active GPU device!\\n\");\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int deviceCount;\n",
    "    cudaGetDeviceCount(&deviceCount);\n",
    "    printf(\"Total devices: %d\\n\\n\", deviceCount);\n",
    "    \n",
    "    // Get current device\n",
    "    int currentDevice;\n",
    "    cudaGetDevice(&currentDevice);\n",
    "    printf(\"Current active device: %d\\n\", currentDevice);\n",
    "    \n",
    "    // Get its properties\n",
    "    cudaDeviceProp prop;\n",
    "    cudaGetDeviceProperties(&prop, currentDevice);\n",
    "    printf(\"Device name: %s\\n\\n\", prop.name);\n",
    "    \n",
    "    // Set device explicitly (useful in multi-GPU systems)\n",
    "    cudaSetDevice(0);\n",
    "    printf(\"Set active device to 0\\n\");\n",
    "    \n",
    "    // Launch kernel on active device\n",
    "    identifyDevice<<<1, 1>>>();\n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5: Calculate Optimal Thread Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cu\n",
    "#include <stdio.h>\n",
    "\n",
    "void printOptimalConfig(int dataSize) {\n",
    "    cudaDeviceProp prop;\n",
    "    cudaGetDeviceProperties(&prop, 0);\n",
    "    \n",
    "    printf(\"\\nOptimal Configuration for %d elements:\\n\", dataSize);\n",
    "    printf(\"----------------------------------------\\n\");\n",
    "    \n",
    "    // Common thread block sizes\n",
    "    int blockSizes[] = {128, 256, 512, 1024};\n",
    "    \n",
    "    for (int i = 0; i < 4; i++) {\n",
    "        int threadsPerBlock = blockSizes[i];\n",
    "        \n",
    "        if (threadsPerBlock > prop.maxThreadsPerBlock) {\n",
    "            continue;\n",
    "        }\n",
    "        \n",
    "        int numBlocks = (dataSize + threadsPerBlock - 1) / threadsPerBlock;\n",
    "        int totalThreads = numBlocks * threadsPerBlock;\n",
    "        int wastedThreads = totalThreads - dataSize;\n",
    "        float efficiency = 100.0 * dataSize / totalThreads;\n",
    "        \n",
    "        printf(\"Threads/Block: %4d | Blocks: %6d | \"\n",
    "               \"Total Threads: %8d | Wasted: %6d (%.1f%% efficient)\\n\",\n",
    "               threadsPerBlock, numBlocks, totalThreads, wastedThreads, efficiency);\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    printOptimalConfig(10000);\n",
    "    printOptimalConfig(1000000);\n",
    "    printOptimalConfig(1048576);  // Power of 2\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical Exercise\n",
    "\n",
    "**Exercise 1:** Write a program that displays memory information for your GPU in a human-readable format (GB, MB, KB).\n",
    "\n",
    "**Exercise 2:** Calculate the theoretical peak FLOPS (floating-point operations per second) of your GPU based on clock rate and core count.\n",
    "\n",
    "**Exercise 3:** Create a function that recommends the best block size for a given problem size.\n",
    "\n",
    "**Exercise 4:** Compare the specifications of your GPU with NVIDIA's published specs online."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cu\n",
    "// Your solution here\n",
    "#include <stdio.h>\n",
    "\n",
    "int main() {\n",
    "    // TODO: Implement your solution\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **cudaGetDeviceCount()** returns the number of CUDA-capable GPUs\n",
    "2. **cudaGetDeviceProperties()** retrieves detailed GPU information\n",
    "3. **cudaSetDevice()** selects which GPU to use (important for multi-GPU systems)\n",
    "4. **Compute capability** indicates the GPU architecture and available features\n",
    "5. Understanding GPU limits (max threads, blocks, memory) is crucial for optimal performance\n",
    "6. Different GPUs have different capabilities - always query before making assumptions\n",
    "7. **Warp size** is always 32 threads on current NVIDIA GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "In the next notebook, we'll learn how to:\n",
    "- Perform vector addition on the GPU\n",
    "- Allocate and manage GPU memory\n",
    "- Transfer data between host and device\n",
    "- Calculate proper thread indices\n",
    "\n",
    "Continue to: **03_vector_add.ipynb**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "*Use this space to write your own notes and observations:*\n",
    "\n",
    "---\n",
    "\n",
    "My GPU specifications:\n",
    "- Device Name: \n",
    "- Compute Capability: \n",
    "- Global Memory: \n",
    "- SM Count: \n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
