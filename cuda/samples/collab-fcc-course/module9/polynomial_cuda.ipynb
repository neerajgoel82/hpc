{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Polynomial Cuda",
        "",
        "**FreeCodeCamp CUDA Course - Module 9**",
        "",
        "Original Course: [https://www.youtube.com/watch?v=86FAWCzIe_4](https://www.youtube.com/watch?v=86FAWCzIe_4)",
        "Source File: `polynomial_cuda.cu`",
        "",
        "---",
        "",
        "## Overview",
        "",
        "CUDA programming concepts and implementation.",
        "",
        "---",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Learning Objectives",
        "",
        "By the end of this notebook, you will:",
        "",
        "1. Understand CUDA kernel syntax and execution",
        "",
        "---",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup: Google Colab GPU",
        "",
        "First, ensure you have enabled GPU in Colab:",
        "1. Go to **Runtime** \u2192 **Change runtime type**",
        "2. Select **T4 GPU** as Hardware accelerator",
        "3. Click **Save**",
        "",
        "Let's verify CUDA is available:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check GPU availability",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now install the nvcc4jupyter plugin to compile CUDA code inline:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install nvcc4jupyter for inline CUDA compilation",
        "!pip install nvcc4jupyter -q",
        "%load_ext nvcc4jupyter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key Concepts",
        "",
        "- **Kernel Function**: Uses `__global__` qualifier for GPU execution",
        "- **Kernel Launch**: Syntax `kernel<<<blocks, threads>>>(...)`",
        "",
        "---",
        "",
        "## CUDA Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%cu",
        "#include <torch/extension.h>",
        "#include <cuda.h>",
        "#include <cuda_runtime.h>",
        "",
        "template <typename scalar_t>",
        "__global__ void polynomial_activation_kernel(",
        "    const scalar_t* __restrict__ x,",
        "    scalar_t* __restrict__ output,",
        "    size_t size) {",
        "    ",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;",
        "    if (idx < size) {",
        "        scalar_t val = x[idx];",
        "        output[idx] = val * val + val + 1; // x^2 + x + 1",
        "    }",
        "}",
        "",
        "torch::Tensor polynomial_activation_cuda(torch::Tensor x) {",
        "    auto output = torch::empty_like(x);",
        "    int threads = 1024;",
        "    int blocks = (x.numel() + threads - 1) / threads;",
        "",
        "    AT_DISPATCH_FLOATING_TYPES(x.type(), \"polynomial_activation_cuda\", ([&] {",
        "        polynomial_activation_kernel<scalar_t><<<blocks, threads>>>(",
        "            x.data_ptr<scalar_t>(),",
        "            output.data_ptr<scalar_t>(),",
        "            x.numel()",
        "        );",
        "    }));",
        "",
        "    return output;",
        "}",
        "",
        "PYBIND11_MODULE(TORCH_EXTENSION_NAME, m) {",
        "    m.def(\"polynomial_activation\", &polynomial_activation_cuda, \"Polynomial activation (CUDA)\");",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercises",
        "",
        "Try these modifications:",
        "",
        "1. **Modify Parameters**: Change kernel launch parameters and observe effects",
        "",
        "2. **Add Error Checking**: Implement CUDA error checking for all API calls",
        "",
        "3. **Performance Measurement**: Add timing code to measure execution time",
        "",
        "4. **Extend Functionality**: Add new features building on this example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---",
        "",
        "## Key Takeaways",
        "",
        "- CUDA enables massive parallelism for compute-intensive tasks",
        "- Proper memory management is crucial for performance",
        "- Understanding the thread hierarchy helps write efficient kernels",
        "- Always synchronize when needed to ensure correctness",
        "",
        "---",
        "",
        "## Next Steps",
        "",
        "Continue to the next notebook in Module 9 to learn more CUDA concepts!",
        "",
        "---",
        "",
        "## Notes",
        "",
        "*Use this space for your learning notes:*",
        "",
        "",
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}