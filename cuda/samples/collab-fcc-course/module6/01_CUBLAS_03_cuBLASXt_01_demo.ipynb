{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 01 Demo",
        "",
        "**FreeCodeCamp CUDA Course - Module 6**",
        "",
        "Original Course: [https://www.youtube.com/watch?v=86FAWCzIe_4](https://www.youtube.com/watch?v=86FAWCzIe_4)",
        "Source File: `01_demo.cu`",
        "",
        "---",
        "",
        "## Overview",
        "",
        "CUDA programming concepts and implementation.",
        "",
        "---",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Learning Objectives",
        "",
        "By the end of this notebook, you will:",
        "",
        "1. Leverage cuBLAS library for optimized operations",
        "",
        "---",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup",
        "",
        "Make sure you've completed the setup from the first notebook (GPU enabled, nvcc4jupyter installed).",
        "",
        "---",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CUDA Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%cu",
        "#include <cublasXt.h>",
        "#include <cublas_v2.h>",
        "#include <cuda_runtime.h>",
        "#include <iostream>",
        "#include <cstdlib>",
        "#include <ctime>",
        "",
        "// Define matrix dimensions",
        "const int M = 1024 / 4;",
        "const int N = 1024 / 4;",
        "const int K = 1024 / 4;",
        "",
        "#define CHECK_CUBLAS(call) { cublasStatus_t err = call; if (err != CUBLAS_STATUS_SUCCESS) { std::cerr << \"Error in \" << #call << \", line \" << __LINE__ << std::endl; exit(1); } }",
        "",
        "int main() {",
        "    // Initialize random number generator",
        "    srand(time(0));",
        "",
        "    // Allocate host memory for matrices",
        "    float* A_host = new float[M * K];",
        "    float* B_host = new float[K * N];",
        "    float* C_host_cpu = new float[M * N];",
        "    float* C_host_gpu = new float[M * N];",
        "",
        "    // Initialize matrices with random values",
        "    for (int i = 0; i < M * K; i++) {",
        "        A_host[i] = (float)rand() / RAND_MAX;",
        "    }",
        "    for (int i = 0; i < K * N; i++) {",
        "        B_host[i] = (float)rand() / RAND_MAX;",
        "    }",
        "",
        "    // Perform CPU-based matrix multiplication",
        "    float alpha = 1.0f;",
        "    float beta = 0.0f;",
        "    for (int i = 0; i < M; i++) {",
        "        for (int j = 0; j < N; j++) {",
        "            C_host_cpu[i * N + j] = 0.0f;",
        "            for (int k = 0; k < K; k++) {",
        "                C_host_cpu[i * N + j] += A_host[i * K + k] * B_host[k * N + j];",
        "            }",
        "        }",
        "    }",
        "    ",
        "    cublasXtHandle_t handle;",
        "    CHECK_CUBLAS(cublasXtCreate(&handle));",
        "",
        "    int devices[1] = {0};",
        "    CHECK_CUBLAS(cublasXtDeviceSelect(handle, 1, devices));",
        "",
        "    // Warmup run",
        "    CHECK_CUBLAS(cublasXtSgemm(handle, CUBLAS_OP_N, CUBLAS_OP_N, N, M, K, &alpha, B_host, N, A_host, K, &beta, C_host_gpu, N));",
        "",
        "",
        "    // Compare results",
        "    float max_diff = 1e-4f;",
        "    for (int i = 0; i < M * N; i++) {",
        "        float diff = std::abs(C_host_cpu[i] - C_host_gpu[i]);",
        "        if (diff > max_diff) {",
        "            std::cout << \"i: \" << i << \" CPU: \" << C_host_cpu[i] << \", GPU: \" << C_host_gpu[i] << std::endl;",
        "            ",
        "        }",
        "    }",
        "    std::cout << \"Maximum difference between CPU and GPU results: \" << max_diff << std::endl;",
        "",
        "    // Free memory",
        "    delete[] A_host;",
        "    delete[] B_host;",
        "    delete[] C_host_cpu;",
        "    delete[] C_host_gpu;",
        "",
        "",
        "    return 0;",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercises",
        "",
        "Try these modifications:",
        "",
        "1. **Modify Parameters**: Change kernel launch parameters and observe effects",
        "",
        "2. **Add Error Checking**: Implement CUDA error checking for all API calls",
        "",
        "3. **Performance Measurement**: Add timing code to measure execution time",
        "",
        "4. **Extend Functionality**: Add new features building on this example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---",
        "",
        "## Key Takeaways",
        "",
        "- CUDA enables massive parallelism for compute-intensive tasks",
        "- Proper memory management is crucial for performance",
        "- Understanding the thread hierarchy helps write efficient kernels",
        "- Always synchronize when needed to ensure correctness",
        "",
        "---",
        "",
        "## Next Steps",
        "",
        "Continue to the next notebook in Module 6 to learn more CUDA concepts!",
        "",
        "---",
        "",
        "## Notes",
        "",
        "*Use this space for your learning notes:*",
        "",
        "",
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}